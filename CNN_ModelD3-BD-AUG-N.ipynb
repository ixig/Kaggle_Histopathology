{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd2e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import *\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554c5265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d028028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "HDF5_FILE = 'data_tf.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce1e8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMG_SHAPE = (96, 96, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2bc132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join(DATA_DIR, HDF5_FILE)\n",
    "ds_x = tfio.IODataset.from_hdf5(data_file, '/x_train')\n",
    "ds_y = tfio.IODataset.from_hdf5(data_file, '/y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c5be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to float and scale to [0, 1)\n",
    "ds_x = ds_x.map(lambda x: tf.image.convert_image_dtype(x, tf.float32))\n",
    "# ds_x = ds_x.map(lambda x: tf.image.crop_to_bounding_box(x, 8, 8, 80, 80))\n",
    "# ds_x = ds_images.map(lambda x: tf.image.per_image_standardization(x))\n",
    "ds_xc = ds_x.map(lambda x: tf.add(x, tf.random.normal(tf.shape(x), 0, 0.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "819b1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_xy = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "ds_xy = ds_xy.shuffle(BATCH_SIZE*2)\n",
    "\n",
    "ds_xcy = tf.data.Dataset.zip((ds_xc, ds_y))\n",
    "ds_xcy = ds_xcy.shuffle(BATCH_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9345a275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220025, 198022)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds_len = ds_xy.reduce(0, lambda x, _: x + 1).numpy()\n",
    "ds_len = 220025\n",
    "train_len = int(0.9 * ds_len)\n",
    "\n",
    "ds_train = ds_xy.take(train_len)\n",
    "ds_trainc = ds_xcy.take(train_len)\n",
    "ds_test = ds_xy.skip(train_len)\n",
    "\n",
    "ds_len, train_len"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45b846f1",
   "metadata": {},
   "source": [
    "ds_train = ds_xy.take(20000)\n",
    "ds_trainc = ds_xcy.take(20000)\n",
    "ds_test = ds_xy.skip(20000).take(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d41a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import control_flow_util\n",
    "from keras.layers.preprocessing.image_preprocessing import transform, get_rotation_matrix\n",
    "import numpy as np\n",
    "\n",
    "H_AXIS = -3\n",
    "W_AXIS = -2\n",
    "\n",
    "class RandomRot90(tf.keras.layers.RandomRotation):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        if training is None:\n",
    "            training = backend.learning_phase()\n",
    "\n",
    "        inputs = tf.convert_to_tensor(inputs)\n",
    "        original_shape = inputs.shape\n",
    "        unbatched = inputs.shape.rank == 3\n",
    "        # The transform op only accepts rank 4 inputs, so if we have an unbatched\n",
    "        # image, we need to temporarily expand dims to a batch.\n",
    "        if unbatched:\n",
    "            inputs = tf.expand_dims(inputs, 0)\n",
    "\n",
    "        def random_rotated_inputs():\n",
    "            \"\"\"Rotated inputs with random ops.\"\"\"\n",
    "            inputs_shape = tf.shape(inputs)\n",
    "            batch_size = inputs_shape[0]\n",
    "            img_hd = tf.cast(inputs_shape[H_AXIS], tf.float32)\n",
    "            img_wd = tf.cast(inputs_shape[W_AXIS], tf.float32)\n",
    "            #min_angle = self.lower * 2. * np.pi\n",
    "            #max_angle = self.upper * 2. * np.pi\n",
    "            angles = self._rng.uniform(\n",
    "                shape=[batch_size], minval=self.lower, maxval=self.upper)            \n",
    "            angles = tf.math.floordiv(angles, 0.25)\n",
    "            angles = tf.multiply(angles, 0.5 * np.pi)\n",
    "            return transform(\n",
    "                inputs,\n",
    "                get_rotation_matrix(angles, img_hd, img_wd),\n",
    "                fill_mode=self.fill_mode,\n",
    "                fill_value=self.fill_value,\n",
    "                interpolation=self.interpolation)\n",
    "\n",
    "        output = control_flow_util.smart_cond(training, random_rotated_inputs,\n",
    "                                              lambda: inputs)\n",
    "        if unbatched:\n",
    "              output = tf.squeeze(output, 0)\n",
    "        output.set_shape(original_shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0431df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),\n",
    "    RandomRot90((0., 1.), fill_mode='constant')\n",
    "    # RandomZoom(0.2, 0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca6c116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(data_aug)\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(1e-4))) #, input_shape=(X_train.shape[1:])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D (pool_size=(2, 2)))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D (pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14a917e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3095/3095 - 158s - loss: 0.4846 - accuracy: 0.8165 - val_loss: 0.7085 - val_accuracy: 0.7270\n",
      "Epoch 2/8\n",
      "3095/3095 - 154s - loss: 0.3512 - accuracy: 0.8673 - val_loss: 0.6130 - val_accuracy: 0.7875\n",
      "Epoch 3/8\n",
      "3095/3095 - 154s - loss: 0.3077 - accuracy: 0.8898 - val_loss: 0.8992 - val_accuracy: 0.7449\n",
      "Epoch 4/8\n",
      "3095/3095 - 154s - loss: 0.2922 - accuracy: 0.8976 - val_loss: 0.9055 - val_accuracy: 0.7564\n",
      "Epoch 5/8\n",
      "3095/3095 - 154s - loss: 0.2856 - accuracy: 0.9020 - val_loss: 1.1763 - val_accuracy: 0.7523\n",
      "Epoch 6/8\n",
      "3095/3095 - 154s - loss: 0.2803 - accuracy: 0.9039 - val_loss: 0.6371 - val_accuracy: 0.7912\n",
      "Epoch 7/8\n",
      "3095/3095 - 154s - loss: 0.2762 - accuracy: 0.9062 - val_loss: 0.7589 - val_accuracy: 0.7964\n",
      "Epoch 8/8\n",
      "3095/3095 - 154s - loss: 0.2733 - accuracy: 0.9077 - val_loss: 0.7881 - val_accuracy: 0.7845\n"
     ]
    }
   ],
   "source": [
    "ds_trainc = ds_trainc.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=1e-3),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_trainc,\n",
    "                    epochs=8,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd4ca1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3095/3095 - 154s - loss: 0.2257 - accuracy: 0.9300 - val_loss: 0.3018 - val_accuracy: 0.9188\n",
      "Epoch 2/8\n",
      "3095/3095 - 153s - loss: 0.2168 - accuracy: 0.9337 - val_loss: 1.0304 - val_accuracy: 0.7823\n",
      "Epoch 3/8\n",
      "3095/3095 - 153s - loss: 0.2136 - accuracy: 0.9350 - val_loss: 0.4646 - val_accuracy: 0.8511\n",
      "Epoch 4/8\n",
      "3095/3095 - 154s - loss: 0.2106 - accuracy: 0.9364 - val_loss: 0.3104 - val_accuracy: 0.8852\n",
      "Epoch 5/8\n",
      "3095/3095 - 153s - loss: 0.2091 - accuracy: 0.9372 - val_loss: 0.6924 - val_accuracy: 0.8023\n",
      "Epoch 6/8\n",
      "3095/3095 - 153s - loss: 0.2074 - accuracy: 0.9382 - val_loss: 0.2589 - val_accuracy: 0.9146\n",
      "Epoch 7/8\n",
      "3095/3095 - 153s - loss: 0.2067 - accuracy: 0.9387 - val_loss: 0.3367 - val_accuracy: 0.8952\n",
      "Epoch 8/8\n",
      "3095/3095 - 153s - loss: 0.2044 - accuracy: 0.9395 - val_loss: 0.2735 - val_accuracy: 0.9129\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=8,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "968da4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1548/1548 - 154s - loss: 0.1673 - accuracy: 0.9534 - val_loss: 0.2605 - val_accuracy: 0.9227\n",
      "Epoch 2/8\n",
      "1548/1548 - 151s - loss: 0.1575 - accuracy: 0.9562 - val_loss: 0.1511 - val_accuracy: 0.9596\n",
      "Epoch 3/8\n",
      "1548/1548 - 151s - loss: 0.1526 - accuracy: 0.9575 - val_loss: 0.1727 - val_accuracy: 0.9496\n",
      "Epoch 4/8\n",
      "1548/1548 - 151s - loss: 0.1497 - accuracy: 0.9580 - val_loss: 0.2010 - val_accuracy: 0.9399\n",
      "Epoch 5/8\n",
      "1548/1548 - 151s - loss: 0.1454 - accuracy: 0.9590 - val_loss: 0.1976 - val_accuracy: 0.9416\n",
      "Epoch 6/8\n",
      "1548/1548 - 151s - loss: 0.1432 - accuracy: 0.9597 - val_loss: 0.1997 - val_accuracy: 0.9382\n",
      "Epoch 7/8\n",
      "1548/1548 - 151s - loss: 0.1414 - accuracy: 0.9601 - val_loss: 0.1379 - val_accuracy: 0.9611\n",
      "Epoch 8/8\n",
      "1548/1548 - 151s - loss: 0.1396 - accuracy: 0.9602 - val_loss: 0.1755 - val_accuracy: 0.9442\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train.unbatch()\n",
    "ds_test = ds_test.unbatch()\n",
    "ds_train = ds_train.batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=2e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=8,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cde878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "774/774 - 156s - loss: 0.1292 - accuracy: 0.9640 - val_loss: 0.1238 - val_accuracy: 0.9670\n",
      "Epoch 2/8\n",
      "774/774 - 151s - loss: 0.1285 - accuracy: 0.9644 - val_loss: 0.1224 - val_accuracy: 0.9672\n",
      "Epoch 3/8\n",
      "774/774 - 151s - loss: 0.1269 - accuracy: 0.9647 - val_loss: 0.1213 - val_accuracy: 0.9677\n",
      "Epoch 4/8\n",
      "774/774 - 152s - loss: 0.1270 - accuracy: 0.9646 - val_loss: 0.1206 - val_accuracy: 0.9677\n",
      "Epoch 5/8\n",
      "774/774 - 152s - loss: 0.1256 - accuracy: 0.9651 - val_loss: 0.1202 - val_accuracy: 0.9680\n",
      "Epoch 6/8\n",
      "774/774 - 152s - loss: 0.1246 - accuracy: 0.9654 - val_loss: 0.1230 - val_accuracy: 0.9663\n",
      "Epoch 7/8\n",
      "774/774 - 151s - loss: 0.1241 - accuracy: 0.9650 - val_loss: 0.1236 - val_accuracy: 0.9666\n",
      "Epoch 8/8\n",
      "774/774 - 152s - loss: 0.1240 - accuracy: 0.9657 - val_loss: 0.1172 - val_accuracy: 0.9686\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train.unbatch()\n",
    "ds_test = ds_test.unbatch()\n",
    "ds_train = ds_train.batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=5e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=8,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf7bc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3095/3095 - 154s - loss: 0.1393 - accuracy: 0.9596 - val_loss: 0.1546 - val_accuracy: 0.9511\n",
      "Epoch 2/5\n",
      "3095/3095 - 153s - loss: 0.1371 - accuracy: 0.9601 - val_loss: 0.1290 - val_accuracy: 0.9630\n",
      "Epoch 3/5\n",
      "3095/3095 - 153s - loss: 0.1365 - accuracy: 0.9600 - val_loss: 0.1507 - val_accuracy: 0.9550\n",
      "Epoch 4/5\n",
      "3095/3095 - 153s - loss: 0.1356 - accuracy: 0.9602 - val_loss: 0.1244 - val_accuracy: 0.9645\n",
      "Epoch 5/5\n",
      "3095/3095 - 153s - loss: 0.1341 - accuracy: 0.9608 - val_loss: 0.1295 - val_accuracy: 0.9624\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train.unbatch()\n",
    "ds_test = ds_test.unbatch()\n",
    "ds_train = ds_train.batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=5,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02a06b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3095/3095 - 153s - loss: 0.2232 - accuracy: 0.9214 - val_loss: 2.1564 - val_accuracy: 0.7285\n",
      "Epoch 2/2\n",
      "3095/3095 - 153s - loss: 0.2088 - accuracy: 0.9283 - val_loss: 1.8633 - val_accuracy: 0.7327\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_trainc,\n",
    "                    epochs=2,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a2884f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "774/774 - 152s - loss: 0.1356 - accuracy: 0.9595 - val_loss: 0.1260 - val_accuracy: 0.9640\n",
      "Epoch 2/5\n",
      "774/774 - 151s - loss: 0.1260 - accuracy: 0.9637 - val_loss: 0.1198 - val_accuracy: 0.9666\n",
      "Epoch 3/5\n",
      "774/774 - 152s - loss: 0.1231 - accuracy: 0.9650 - val_loss: 0.1177 - val_accuracy: 0.9667\n",
      "Epoch 4/5\n",
      "774/774 - 152s - loss: 0.1203 - accuracy: 0.9659 - val_loss: 0.1153 - val_accuracy: 0.9677\n",
      "Epoch 5/5\n",
      "774/774 - 152s - loss: 0.1190 - accuracy: 0.9663 - val_loss: 0.1176 - val_accuracy: 0.9677\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train.unbatch()\n",
    "ds_test = ds_test.unbatch()\n",
    "ds_train = ds_train.batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=5e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=5,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb91f153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "387/387 - 162s - loss: 0.1260 - accuracy: 0.9638 - val_loss: 0.1485 - val_accuracy: 0.9561\n",
      "Epoch 2/2\n",
      "387/387 - 153s - loss: 0.1244 - accuracy: 0.9640 - val_loss: 0.1689 - val_accuracy: 0.9481\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train.unbatch()\n",
    "ds_test = ds_test.unbatch()\n",
    "ds_train = ds_train.batch(512).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(512).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=5e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=2,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f0dddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "387/387 - 154s - loss: 0.1161 - accuracy: 0.9672 - val_loss: 0.1166 - val_accuracy: 0.9681\n",
      "Epoch 2/5\n",
      "387/387 - 153s - loss: 0.1135 - accuracy: 0.9684 - val_loss: 0.1114 - val_accuracy: 0.9690\n",
      "Epoch 3/5\n",
      "387/387 - 153s - loss: 0.1128 - accuracy: 0.9683 - val_loss: 0.1116 - val_accuracy: 0.9694\n",
      "Epoch 4/5\n",
      "387/387 - 153s - loss: 0.1119 - accuracy: 0.9683 - val_loss: 0.1111 - val_accuracy: 0.9692\n",
      "Epoch 5/5\n",
      "387/387 - 153s - loss: 0.1110 - accuracy: 0.9688 - val_loss: 0.1116 - val_accuracy: 0.9694\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=5e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=5,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94285494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3095/3095 - 153s - loss: 0.2198 - accuracy: 0.9227 - val_loss: 2.9547 - val_accuracy: 0.7058\n",
      "Epoch 2/2\n",
      "3095/3095 - 152s - loss: 0.2033 - accuracy: 0.9292 - val_loss: 2.2697 - val_accuracy: 0.7373\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=5e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_trainc,\n",
    "                    epochs=2,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0601055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "387/387 - 154s - loss: 0.1372 - accuracy: 0.9580 - val_loss: 0.1240 - val_accuracy: 0.9651\n",
      "Epoch 2/5\n",
      "387/387 - 153s - loss: 0.1242 - accuracy: 0.9635 - val_loss: 0.1197 - val_accuracy: 0.9661\n",
      "Epoch 3/5\n",
      "387/387 - 153s - loss: 0.1215 - accuracy: 0.9645 - val_loss: 0.1174 - val_accuracy: 0.9666\n",
      "Epoch 4/5\n",
      "387/387 - 153s - loss: 0.1186 - accuracy: 0.9660 - val_loss: 0.1159 - val_accuracy: 0.9675\n",
      "Epoch 5/5\n",
      "387/387 - 153s - loss: 0.1172 - accuracy: 0.9662 - val_loss: 0.1138 - val_accuracy: 0.9680\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=5,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a57a766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "387/387 - 154s - loss: 0.1156 - accuracy: 0.9671 - val_loss: 0.1202 - val_accuracy: 0.9658\n",
      "Epoch 2/2\n",
      "387/387 - 153s - loss: 0.1129 - accuracy: 0.9682 - val_loss: 0.1106 - val_accuracy: 0.9694\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=5e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=2,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d441b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "387/387 - 153s - loss: 0.1105 - accuracy: 0.9687 - val_loss: 0.1089 - val_accuracy: 0.9696\n",
      "Epoch 2/5\n",
      "387/387 - 153s - loss: 0.1102 - accuracy: 0.9687 - val_loss: 0.1089 - val_accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "387/387 - 153s - loss: 0.1099 - accuracy: 0.9693 - val_loss: 0.1083 - val_accuracy: 0.9703\n",
      "Epoch 4/5\n",
      "387/387 - 153s - loss: 0.1100 - accuracy: 0.9691 - val_loss: 0.1082 - val_accuracy: 0.9700\n",
      "Epoch 5/5\n",
      "387/387 - 153s - loss: 0.1091 - accuracy: 0.9694 - val_loss: 0.1082 - val_accuracy: 0.9696\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=Adam(learning_rate=1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=5,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff77b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "387/387 - 154s - loss: 0.1096 - accuracy: 0.9691 - val_loss: 0.1089 - val_accuracy: 0.9697\n",
      "Epoch 2/5\n",
      "387/387 - 153s - loss: 0.1092 - accuracy: 0.9691 - val_loss: 0.1090 - val_accuracy: 0.9696\n",
      "Epoch 3/5\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=SGD(learning_rate=1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    epochs=5,\n",
    "                    verbose=2, \n",
    "                    validation_data=ds_test\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ae0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
